{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb53e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1750b",
   "metadata": {},
   "source": [
    "## Library Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets library\n",
    "import fiftyone as fo\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4695bc",
   "metadata": {},
   "source": [
    "### Vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_DS_PATH = \"../food_waste_part_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7aa86",
   "metadata": {},
   "source": [
    "### Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ingredients_to_english(ingredient_list, translation_dict):\n",
    "    \"\"\"Maps German ingredient names to English using a provided dictionary.\"\"\"\n",
    "    mapped_list = []\n",
    "    for ingredient in ingredient_list:\n",
    "        # Strip whitespace before looking up in the dictionary\n",
    "        stripped_ingredient = ingredient.strip()\n",
    "        # Use get() with a default value to handle cases where the ingredient is not in the dictionary\n",
    "        mapped_list.append(\n",
    "            translation_dict.get(stripped_ingredient, stripped_ingredient)\n",
    "        )\n",
    "    return mapped_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "hf_dataset = load_dataset(\"Dldermann/food-waste-dataset-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56778ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ds = fo.Dataset.from_dir(\n",
    "    dataset_dir=OLD_DS_PATH, dataset_type=fo.types.FiftyOneDataset\n",
    ")\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5eb69f",
   "metadata": {},
   "source": [
    "### Map & Translate Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_mapping = {\n",
    "#     'bonid': 'bonid',\n",
    "#     'image': 'image',\n",
    "#     'Bon_ID': 'bon_id',\n",
    "#     'Artikelnummer': 'article_number',\n",
    "#     'Artikel': 'ingredient_name',\n",
    "#     'Stückartikel': 'piece_article',\n",
    "#     'Anzahl_Kellen': 'number_of_portions',\n",
    "#     'Gewicht_Kelle': 'weight_per_portion',\n",
    "#     'Gewicht_Teller': 'weight_per_plate',\n",
    "#     'kcal_Teller': 'kcal_per_plate',\n",
    "#     'kj_Teller': 'kj_per_plate',\n",
    "#     'Fett_Teller': 'fat_per_plate',\n",
    "#     'ges_Fettsäuren_Teller': 'saturated_fat_per_plate',\n",
    "#     'Kohlenhydrate_Teller': 'carbohydrates_per_plate',\n",
    "#     'Zucker_Teller': 'sugar_per_plate',\n",
    "#     'Eiweiß_Teller': 'protein_per_plate',\n",
    "#     'Salz_Teller': 'salt_per_plate',\n",
    "#     'Menge_Rückläufer': 'return_quantity',\n",
    "#     'Prozent_Rückläufer': 'return_percentage',\n",
    "#     'Gericht': 'dish',\n",
    "#     'Portionsgröße': 'portion_size',\n",
    "#     'Gewicht_vorher': 'weight_before',\n",
    "#     'kcal_vorher': 'kcal_before',\n",
    "#     'kj_vorher': 'kj_before',\n",
    "#     'Fett_vorher': 'fat_before',\n",
    "#     'ges_Fettsäuren_vorher': 'saturated_fat_before',\n",
    "#     'Kohlenhydrate_vorher': 'carbohydrates_before',\n",
    "#     'Zucker_vorher': 'sugar_before',\n",
    "#     'Eiweiß_vorher': 'protein_before',\n",
    "#     'Salz_vorher': 'salt_before',\n",
    "#     'Gewicht_nachher': 'weight_after',\n",
    "#     'kcal_nachher': 'kcal_after',\n",
    "#     'kj_nachher': 'kj_after',\n",
    "#     'Fett_nachher': 'fat_after',\n",
    "#     'ges_fettsäuren_nachher': 'saturated_fat_after',\n",
    "#     'Kohlenhydrate_nachher': 'carbohydrates_after',\n",
    "#     'Zucker_nachher': 'sugar_after',\n",
    "#     'Eiweiß_nachher': 'protein_after',\n",
    "#     'Salz_nachher': 'salt_after'\n",
    "# }\n",
    "\n",
    "# # Rename the columns in the dataset\n",
    "# hf_dataset = hf_dataset.rename_columns(feature_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ebd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# german_to_english_ingredients_hyphenated = {\n",
    "#     'Fleischbällchen gebrüht': 'poached-meatballs',\n",
    "#     'Reis': 'rice',\n",
    "#     'Paniertes Fischfilet': 'breaded-fish-fillet',\n",
    "#     'Linseneintopf': 'lentil-stew',\n",
    "#     'Apfelmus': 'applesauce',\n",
    "#     'Helle Sauce': 'light-sauce-or-white-sauce',\n",
    "#     'Kartoffelpüree': 'mashed-potatoes',\n",
    "#     'Rinderbraten': 'roast-beef',\n",
    "#     'Semmelknödel': 'bread-dumplings',\n",
    "#     'Grüne Bohnen': 'green-beans',\n",
    "#     'Möhre': 'carrot',\n",
    "#     'Pflanzencreme': 'vegetable-based-cream',\n",
    "#     'Schinken Mettwurst': 'ham-sausage',\n",
    "#     'Paprika': 'paprika-or-bell-pepper',\n",
    "#     'Seelachs': 'pollock-or-coalfish',\n",
    "#     'Bratenjus': 'gravy',\n",
    "#     'Hähnchenstreifen': 'chicken-strips',\n",
    "#     'Eisbergsalat': 'iceberg-lettuce',\n",
    "#     'Rotkohl': 'red-cabbage',\n",
    "#     'Sauerkraut': 'sauerkraut',\n",
    "#     'Reibekuchen': 'potato-pancakes-or-potato-fritters',\n",
    "#     'Krautsalat': 'coleslaw',\n",
    "#     'Schnitzel': 'schnitzel-or-cutlet',\n",
    "#     'Blumenkohl': 'cauliflower',\n",
    "#     'Rostbratwurst': 'grilled-sausage',\n",
    "#     'Braune Sauce': 'brown-sauce',\n",
    "#     'Kartoffeln': 'potatoes',\n",
    "#     'Kartoffelwürfel': 'diced-potatoes',\n",
    "#     'Sahne': 'cream',\n",
    "#     'Zucchini': 'zucchini-or-courgette',\n",
    "#     'Eierspätzle': 'egg-spaetzle)',\n",
    "#     'Pilze': 'mushrooms',\n",
    "#     'Erbsen': 'peas',\n",
    "#     'Wirsing': 'savoy-cabbage',\n",
    "#     'Malzbier-Senf-Sauce': 'malt-beer-mustard-sauce',\n",
    "#     'Dressing Portion': 'dressing-portion',\n",
    "#     'Linsen': 'lentils',\n",
    "#     'Zwiebel': 'onion',\n",
    "#     'Schweinenackenbraten': 'pork-neck-roast',\n",
    "#     'Hähnchen': 'chicken',\n",
    "#     'Tomaten-Curry-Sauce': 'tomato-curry-sauce'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the mapping function to the 'ingredient_name' column in both splits\n",
    "# hf_dataset['train'] = hf_dataset['train'].map(\n",
    "#     lambda example: {'ingredient_name': map_ingredients_to_english(example['ingredient_name'], german_to_english_ingredients_hyphenated)}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f122184",
   "metadata": {},
   "source": [
    "### Move data to fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fiftyone as fo\n",
    "# import os\n",
    "\n",
    "\n",
    "# # Create a persistent directory for images\n",
    "# persistent_dir = \"fiftyone_images\"\n",
    "# os.makedirs(persistent_dir, exist_ok=True)\n",
    "\n",
    "# # Create FiftyOne dataset\n",
    "# fiftyone_dataset = fo.Dataset(name=\"food_waste_dataset\")\n",
    "\n",
    "# sample_count = 0\n",
    "# for split in ['train']:\n",
    "#     split_count = 0\n",
    "#     for item in hf_dataset[split]:\n",
    "#         # Save image to persistent directory with unique filename\n",
    "#         image_filename = f\"{split}_{split_count:06d}.jpg\"\n",
    "#         image_path = os.path.join(persistent_dir, image_filename)\n",
    "\n",
    "#         # Save the PIL Image to the persistent file\n",
    "#         item['image'].save(image_path)\n",
    "\n",
    "#         # Create FiftyOne sample\n",
    "#         sample = fo.Sample(filepath=image_path)\n",
    "#         sample['split'] = split\n",
    "\n",
    "#         # Add any additional metadata from the original dataset\n",
    "#         for key, value in item.items():\n",
    "#             if key != 'image':  # Skip the image field since we've handled it\n",
    "#                 sample[key] = value\n",
    "\n",
    "#         fiftyone_dataset.add_sample(sample)\n",
    "#         split_count += 1\n",
    "#         sample_count += 1\n",
    "\n",
    "# print(f\"FiftyOne dataset created with {len(fiftyone_dataset)} samples.\")\n",
    "# print(f\"Images saved to: {os.path.abspath(persistent_dir)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5415c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ds = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"../food_waste_part_1\", dataset_type=fo.types.FiftyOneDataset\n",
    ")\n",
    "new_ds = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"../food_waste_part_2\", dataset_type=fo.types.FiftyOneDataset\n",
    ")\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b3c0c7",
   "metadata": {},
   "source": [
    "### Merge DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = old_ds.clone()\n",
    "dataset_2 = new_ds.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get flattened schemas including nested fields\n",
    "flat_schema1 = dataset_1.get_field_schema(flat=True)\n",
    "flat_schema2 = dataset_2.get_field_schema(flat=True)\n",
    "\n",
    "# Get field names from both schemas\n",
    "fields1 = set(flat_schema1.keys())\n",
    "fields2 = set(flat_schema2.keys())\n",
    "\n",
    "# Fields only in dataset1\n",
    "only_in_dataset1 = fields1 - fields2\n",
    "\n",
    "# Fields only in dataset2\n",
    "only_in_dataset2 = fields2 - fields1\n",
    "\n",
    "# Common fields (check for type differences)\n",
    "common_fields = fields1 & fields2\n",
    "\n",
    "# Check for fields with different types among common fields\n",
    "different_type_fields = []\n",
    "for field_name in common_fields:\n",
    "    field1_type = type(flat_schema1[field_name])\n",
    "    field2_type = type(flat_schema2[field_name])\n",
    "\n",
    "    if field1_type != field2_type:\n",
    "        different_type_fields.append(\n",
    "            {\n",
    "                \"field_name\": field_name,\n",
    "                \"dataset1_type\": field1_type.__name__,\n",
    "                \"dataset2_type\": field2_type.__name__,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Print results\n",
    "print(\"Fields only in dataset1:\")\n",
    "for field in sorted(only_in_dataset1):\n",
    "    print(f\"  {field}\")\n",
    "\n",
    "print(\"\\nFields only in dataset2:\")\n",
    "for field in sorted(only_in_dataset2):\n",
    "    print(f\"  {field}\")\n",
    "\n",
    "print(\"\\nFields with different types:\")\n",
    "for field_info in different_type_fields:\n",
    "    print(\n",
    "        f\"  {field_info['field_name']}: {field_info['dataset1_type']} vs {field_info['dataset2_type']}\"\n",
    "    )\n",
    "\n",
    "# Summary of all differences\n",
    "all_different_fields = (\n",
    "    list(only_in_dataset1)\n",
    "    + list(only_in_dataset2)\n",
    "    + [f[\"field_name\"] for f in different_type_fields]\n",
    ")\n",
    "print(f\"\\nTotal fields with differences: {len(all_different_fields)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fa21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_with_folder_name(folder_path):\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: '{folder_path}' is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    # Get the folder name\n",
    "    folder_name = os.path.basename(os.path.normpath(folder_path))\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Sort the files to ensure consistent numbering\n",
    "    files.sort()\n",
    "\n",
    "    for i, old_file_name in enumerate(files, 1):\n",
    "        # Get the file extension\n",
    "        _, file_extension = os.path.splitext(old_file_name)\n",
    "\n",
    "        # Create the new file name\n",
    "        new_file_name = f\"{folder_name}_{i}{file_extension}\"\n",
    "\n",
    "        # Construct the full paths\n",
    "        old_file_path = os.path.join(folder_path, old_file_name)\n",
    "        new_file_path = os.path.join(folder_path, new_file_name)\n",
    "\n",
    "        # Rename the file\n",
    "        try:\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            # print(f\"Renamed '{old_file_name}' to '{new_file_name}'\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error renaming file {old_file_name}: {e}\")\n",
    "\n",
    "folder_list = [\"../group_1/goulash_0-rice_36-potatoes_0\",\n",
    "               \"../group_1/goulash_0-rice_36-potatoes_0-chickpeas_62\",\n",
    "               \"../group_1/goulash_0-rice_36-potatoes_26-chickpeas_62\",\n",
    "               \"../group_4/Goulash_129\",\n",
    "               \"../group_4/Rice_48\",\n",
    "               \"../group_4/Potatoes_101\",\n",
    "               \"../group_4/Rice_48-Potatoes_101-Goulash_129\",\n",
    "               \"../group_3/goulash_25\",\n",
    "               \"../group_3/goulash_25-rice_31-potatoes_21\",\n",
    "               \"../group_3/goulash_92\",\n",
    "               \"../group_3/goulash_92-rice_66-potatoes_103\",\n",
    "               \"../group_3/potatoes_21\",\n",
    "               \"../group_3/potatoes_103\",\n",
    "               \"../group_3/rice_31\",\n",
    "               \"../group_3/rice_66\"\n",
    "\n",
    "]\n",
    "for folder in folder_list:\n",
    "    rename_files_with_folder_name(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fbbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "# --- Define the filename parsing logic --- #\n",
    "def parse_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    name, _ = os.path.splitext(filename)\n",
    "\n",
    "    parts = name.split('-')\n",
    "\n",
    "    ingredient_names = []\n",
    "    quantities = []\n",
    "\n",
    "    for part in parts:\n",
    "        tokens = part.split('_')\n",
    "        if len(tokens) < 2:\n",
    "            continue\n",
    "\n",
    "        ing_name = tokens[0].lower()  # ensure lowercase\n",
    "        try:\n",
    "            qty = float(tokens[1])\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        ingredient_names.append(ing_name)\n",
    "        quantities.append(qty)\n",
    "\n",
    "    return ingredient_names, quantities\n",
    "\n",
    "# --- Create the dataset --- #\n",
    "dataset = fo.Dataset(\"kool\")\n",
    "\n",
    "# Replace with your actual image directory path\n",
    "image_dir = \"../new_data\"\n",
    "dataset.add_images_dir(image_dir, recursive=True)\n",
    "\n",
    "# --- Add custom fields --- #\n",
    "dataset.add_sample_field(\"ingredient_name\", fo.ListField, subfield=fo.StringField)\n",
    "dataset.add_sample_field(\"return_quantity\", fo.ListField, subfield=fo.FloatField)\n",
    "\n",
    "# --- Populate fields --- #\n",
    "for sample in dataset:\n",
    "    ingredient_names, quantities = parse_filename(sample.filepath)\n",
    "    sample[\"ingredient_name\"] = ingredient_names\n",
    "    sample[\"return_quantity\"] = quantities\n",
    "    sample.save()\n",
    "\n",
    "# --- Show dataset summary --- #\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab987e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    print(sample.ingredient_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94225c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.export('../new_data_ds', fo.types.FiftyOneDataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
